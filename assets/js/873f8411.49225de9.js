"use strict";(globalThis.webpackChunkphysical_ai_book_docs=globalThis.webpackChunkphysical_ai_book_docs||[]).push([[833],{1850(e,n,s){s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module3/isaac","title":"NVIDIA Isaac Sim","description":"NVIDIA Isaac Sim is a robotics simulation application and ecosystem that accelerates AI training and robotics development. Built on NVIDIA Omniverse, it provides photorealistic simulation capabilities essential for Physical AI development.","source":"@site/docs/module3/isaac.md","sourceDirName":"module3","slug":"/module3/isaac","permalink":"/Physical_AI_Book/docs/module3/isaac","draft":false,"unlisted":false,"editUrl":"https://github.com/HM700/Physical_AI_Book/edit/master/frontend/docs/module3/isaac.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: AI-Robot Brain (NVIDIA Isaac)","permalink":"/Physical_AI_Book/docs/module3/intro"},"next":{"title":"Perception Pipelines in Isaac Sim","permalink":"/Physical_AI_Book/docs/module3/perception"}}');var a=s(4848),t=s(8453);const r={sidebar_position:2},o="NVIDIA Isaac Sim",l={},c=[{value:"Introduction to Isaac Sim",id:"introduction-to-isaac-sim",level:2},{value:"Installing Isaac Sim",id:"installing-isaac-sim",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installing Isaac Sim",id:"installing-isaac-sim-1",level:3},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:2},{value:"Core Components",id:"core-components",level:3},{value:"Isaac Sim for ROS 2",id:"isaac-sim-for-ros-2",level:3},{value:"Creating Scenes in Isaac Sim",id:"creating-scenes-in-isaac-sim",level:2},{value:"USD Scene Format",id:"usd-scene-format",level:3},{value:"Python API for Scene Construction",id:"python-api-for-scene-construction",level:3},{value:"Isaac ROS Integration",id:"isaac-ros-integration",level:2},{value:"Perception Pipeline Example",id:"perception-pipeline-example",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Data Generation Script",id:"data-generation-script",level:3},{value:"Isaac Sim ROS 2 Bridge",id:"isaac-sim-ros-2-bridge",level:2},{value:"Best Practices for Isaac Sim",id:"best-practices-for-isaac-sim",level:2},{value:"Exercise",id:"exercise",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})}),"\n",(0,a.jsx)(n.p,{children:"NVIDIA Isaac Sim is a robotics simulation application and ecosystem that accelerates AI training and robotics development. Built on NVIDIA Omniverse, it provides photorealistic simulation capabilities essential for Physical AI development."}),"\n",(0,a.jsx)(n.h2,{id:"introduction-to-isaac-sim",children:"Introduction to Isaac Sim"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Photorealistic rendering with RTX technology"}),"\n",(0,a.jsx)(n.li,{children:"Advanced physics simulation"}),"\n",(0,a.jsx)(n.li,{children:"Synthetic data generation"}),"\n",(0,a.jsx)(n.li,{children:"Integration with Isaac ROS components"}),"\n",(0,a.jsx)(n.li,{children:"Large-scale environment simulation"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"installing-isaac-sim",children:"Installing Isaac Sim"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim requires:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"NVIDIA RTX-capable GPU (recommended)"}),"\n",(0,a.jsx)(n.li,{children:"NVIDIA GPU drivers supporting CUDA 11.8+"}),"\n",(0,a.jsx)(n.li,{children:"Isaac Sim package (available through NVIDIA Developer Program)"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Install NVIDIA drivers\nsudo apt install nvidia-driver-535\n\n# Install CUDA toolkit\nwget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\nsudo sh cuda_11.8.0_520.61.05_linux.run\n"})}),"\n",(0,a.jsx)(n.h3,{id:"installing-isaac-sim-1",children:"Installing Isaac Sim"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim is typically installed as part of the Isaac ROS ecosystem:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Add NVIDIA package repositories\ncurl -sL https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -sL https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \\\n  sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list\n\nsudo apt update\nsudo apt install nvidia-container-toolkit\nsudo systemctl restart docker\n"})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,a.jsx)(n.h3,{id:"core-components",children:"Core Components"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Omniverse Nucleus"}),": Central collaboration platform"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"PhysX"}),": Advanced physics engine"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"RTX Renderer"}),": Realistic lighting and materials"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Synthetic Data Generator"}),": Creates labeled training data"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"isaac-sim-for-ros-2",children:"Isaac Sim for ROS 2"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides bridges to ROS 2 through:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Isaac ROS packages"}),"\n",(0,a.jsx)(n.li,{children:"ROS 2 Bridge for Omniverse"}),"\n",(0,a.jsx)(n.li,{children:"Standard ROS 2 message types"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"creating-scenes-in-isaac-sim",children:"Creating Scenes in Isaac Sim"}),"\n",(0,a.jsx)(n.h3,{id:"usd-scene-format",children:"USD Scene Format"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim uses Universal Scene Description (USD) format for scenes:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-usd",children:'# Example scene.usda\n#usda 1.0\n\ndef Xform "RobotOnTable"\n{\n    def Xform "Table"\n    {\n        def Mesh "Plane"\n        {\n            matrix4d xformOp:transform = ( (10, 0, 0, 0), (0, 1, 0, 0), (0, 0, 10, 0), (0, 0, 0, 1) )\n            rel material:binding = </Materials/Looks/tableMat>\n        }\n    }\n\n    def Xform "Robot"\n    {\n        # Robot definition would go here\n    }\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"python-api-for-scene-construction",children:"Python API for Scene Construction"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim provides a Python API for programmatic scene creation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import omni\nimport carb\nimport omni.kit.commands\nfrom pxr import UsdGeom, Gf\n\n# Create a new stage\nstage = omni.usd.get_context().get_stage()\n\n# Create a prim for the robot\nrobot_prim = stage.DefinePrim("/World/Robot", "Xform")\n\n# Add a chassis\nchassis_prim = stage.DefinePrim("/World/Robot/Chassis", "Cube")\nchassis_prop = UsdGeom.Cube.Get(stage, "/World/Robot/Chassis")\nchassis_prop.GetSizeAttr().Set(1.0)\n\n# Set transform\nchassis_xform = UsdGeom.Xformable(chassis_prim)\nchassis_xform.AddTranslateOp().Set(Gf.Vec3f(0, 0, 0.5))\n\n# Add wheels\nfor i, pos in enumerate([(0.5, 0.4, 0.1), (0.5, -0.4, 0.1), (-0.5, 0.4, 0.1), (-0.5, -0.4, 0.1)]):\n    wheel_prim = stage.DefinePrim(f"/World/Robot/Wheel_{i}", "Cylinder")\n    wheel_geom = UsdGeom.Cylinder.Get(stage, f"/World/Robot/Wheel_{i}")\n    wheel_geom.GetRadiusAttr().Set(0.1)\n    wheel_geom.GetHeightAttr().Set(0.05)\n\n    wheel_xform = UsdGeom.Xformable(wheel_prim)\n    wheel_xform.AddTranslateOp().Set(Gf.Vec3f(*pos))\n'})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-ros-integration",children:"Isaac ROS Integration"}),"\n",(0,a.jsx)(n.p,{children:"Isaac ROS provides hardware-accelerated perception and navigation nodes:"}),"\n",(0,a.jsx)(n.h3,{id:"perception-pipeline-example",children:"Perception Pipeline Example"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# perception_pipeline.py\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom cv_bridge import CvBridge\nimport numpy as np\nimport torch\nimport torchvision.transforms as transforms\n\nclass IsaacPerceptionPipeline(Node):\n    def __init__(self):\n        super().__init__('isaac_perception_pipeline')\n\n        # Initialize CV bridge\n        self.bridge = CvBridge()\n\n        # Subscriptions for Isaac Sim sensors\n        self.rgb_sub = self.create_subscription(\n            Image, '/isaac_sim/camera/rgb/image', self.rgb_callback, 10\n        )\n        self.depth_sub = self.create_subscription(\n            Image, '/isaac_sim/camera/depth/image', self.depth_callback, 10\n        )\n        self.camera_info_sub = self.create_subscription(\n            CameraInfo, '/isaac_sim/camera/rgb/camera_info', self.camera_info_callback, 10\n        )\n\n        # Publishers for processed data\n        self.object_detection_pub = self.create_publisher(\n            # Custom message for detections\n            String, '/object_detections', 10\n        )\n        self.semantic_seg_pub = self.create_publisher(\n            Image, '/semantic_segmentation', 10\n        )\n\n        # Initialize neural network models (Isaac ROS provides optimized versions)\n        self.detector = None  # Would be an Isaac ROS detector\n        self.segmenter = None  # Would be an Isaac ROS segmenter\n\n        # Store camera parameters\n        self.camera_info = None\n\n    def rgb_callback(self, msg):\n        \"\"\"Process RGB image from Isaac Sim.\"\"\"\n        try:\n            # Convert ROS image to OpenCV\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')\n\n            # Perform object detection using Isaac ROS optimized models\n            # detections = self.detector(cv_image)  # Isaac ROS detector\n\n            # Publish results\n            # self.publish_detections(detections)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing RGB image: {str(e)}')\n\n    def depth_callback(self, msg):\n        \"\"\"Process depth image from Isaac Sim.\"\"\"\n        try:\n            # Convert depth image\n            depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='32FC1')\n\n            # Process depth data for obstacle detection, etc.\n            # depth_processed = self.process_depth(depth_image)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing depth image: {str(e)}')\n\n    def camera_info_callback(self, msg):\n        \"\"\"Store camera intrinsic parameters.\"\"\"\n        self.camera_info = msg\n\ndef main(args=None):\n    rclpy.init(args=args)\n    perception_node = IsaacPerceptionPipeline()\n\n    try:\n        rclpy.spin(perception_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        perception_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim excels at generating synthetic training data:"}),"\n",(0,a.jsx)(n.h3,{id:"data-generation-script",children:"Data Generation Script"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# synthetic_data_generator.py\nimport omni\nimport carb\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nimport numpy as np\nimport cv2\nimport json\nfrom PIL import Image\nimport os\n\nclass SyntheticDataGenerator:\n    def __init__(self, output_dir="./synthetic_data"):\n        self.output_dir = output_dir\n        self.sd_helper = SyntheticDataHelper()\n\n        # Create output directories\n        os.makedirs(f"{output_dir}/images", exist_ok=True)\n        os.makedirs(f"{output_dir}/labels", exist_ok=True)\n        os.makedirs(f"{output_dir}/annotations", exist_ok=True)\n\n    def capture_scene_data(self, num_samples=1000):\n        """Capture synthetic data from the scene."""\n        for i in range(num_samples):\n            # Randomize scene (lighting, objects, etc.)\n            self.randomize_scene()\n\n            # Capture RGB, Depth, Segmentation\n            rgb_data = self.sd_helper.get_rgb()\n            depth_data = self.sd_helper.get_depth()\n            seg_data = self.sd_helper.get_segmentation()\n\n            # Save raw data\n            rgb_img = Image.fromarray(rgb_data)\n            rgb_img.save(f"{self.output_dir}/images/rgb_{i:06d}.png")\n\n            depth_img = Image.fromarray(depth_data)\n            depth_img.save(f"{self.output_dir}/images/depth_{i:06d}.png")\n\n            seg_img = Image.fromarray(seg_data)\n            seg_img.save(f"{self.output_dir}/labels/seg_{i:06d}.png")\n\n            # Generate annotations\n            annotations = self.generate_annotations(seg_data)\n            with open(f"{self.output_dir}/annotations/ann_{i:06d}.json", \'w\') as f:\n                json.dump(annotations, f)\n\n            print(f"Generated sample {i+1}/{num_samples}")\n\n    def randomize_scene(self):\n        """Randomize scene parameters for variation."""\n        # Randomize lighting\n        # Randomize object positions\n        # Randomize textures/materials\n        # Add noise to cameras\n        pass\n\n    def generate_annotations(self, segmentation_data):\n        """Generate bounding boxes and labels from segmentation."""\n        # Process segmentation to extract object instances\n        # Generate bounding boxes\n        # Create COCO-style annotations\n        annotations = {\n            "objects": [],\n            "scene_params": {}\n        }\n        return annotations\n\n# Usage\ngenerator = SyntheticDataGenerator()\ngenerator.capture_scene_data(num_samples=1000)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-sim-ros-2-bridge",children:"Isaac Sim ROS 2 Bridge"}),"\n",(0,a.jsx)(n.p,{children:"Connecting Isaac Sim to ROS 2 requires specific bridge configuration:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# isaac_sim_bridge.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Odometry\nfrom sensor_msgs.msg import Image, LaserScan\nfrom nav_msgs.msg import Odometry\nimport numpy as np\n\nclass IsaacSimBridge(Node):\n    def __init__(self):\n        super().__init__('isaac_sim_bridge')\n\n        # ROS 2 publishers for Isaac Sim data\n        self.odom_pub = self.create_publisher(Odometry, '/isaac_sim/odom', 10)\n        self.rgb_pub = self.create_publisher(Image, '/isaac_sim/camera/rgb', 10)\n        self.lidar_pub = self.create_publisher(LaserScan, '/isaac_sim/lidar', 10)\n\n        # ROS 2 subscribers for robot control\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, '/cmd_vel', self.cmd_vel_callback, 10\n        )\n\n        # Timer for publishing simulated sensor data\n        self.pub_timer = self.create_timer(0.1, self.publish_sensor_data)\n\n        # Robot state\n        self.robot_pose = [0.0, 0.0, 0.0]  # x, y, theta\n        self.robot_twist = [0.0, 0.0]      # linear, angular\n\n    def cmd_vel_callback(self, msg):\n        \"\"\"Handle velocity commands from ROS 2.\"\"\"\n        # In Isaac Sim, this would update the robot's joint velocities\n        self.robot_twist[0] = msg.linear.x\n        self.robot_twist[1] = msg.angular.z\n\n        # Update robot pose based on differential drive kinematics\n        dt = 0.1  # Assuming 10Hz update rate\n        dx = self.robot_twist[0] * np.cos(self.robot_pose[2]) * dt\n        dy = self.robot_twist[0] * np.sin(self.robot_pose[2]) * dt\n        dtheta = self.robot_twist[1] * dt\n\n        self.robot_pose[0] += dx\n        self.robot_pose[1] += dy\n        self.robot_pose[2] += dtheta\n\n    def publish_sensor_data(self):\n        \"\"\"Publish simulated sensor data.\"\"\"\n        # Publish odometry\n        odom_msg = Odometry()\n        odom_msg.header.stamp = self.get_clock().now().to_msg()\n        odom_msg.header.frame_id = 'odom'\n        odom_msg.child_frame_id = 'base_link'\n\n        # Set position\n        odom_msg.pose.pose.position.x = self.robot_pose[0]\n        odom_msg.pose.pose.position.y = self.robot_pose[1]\n        # Convert theta to quaternion\n        from tf_transformations import quaternion_from_euler\n        quat = quaternion_from_euler(0, 0, self.robot_pose[2])\n        odom_msg.pose.pose.orientation.x = quat[0]\n        odom_msg.pose.pose.orientation.y = quat[1]\n        odom_msg.pose.pose.orientation.z = quat[2]\n        odom_msg.pose.pose.orientation.w = quat[3]\n\n        # Set velocities\n        odom_msg.twist.twist.linear.x = self.robot_twist[0]\n        odom_msg.twist.twist.angular.z = self.robot_twist[1]\n\n        self.odom_pub.publish(odom_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    bridge_node = IsaacSimBridge()\n\n    try:\n        rclpy.spin(bridge_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        bridge_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"best-practices-for-isaac-sim",children:"Best Practices for Isaac Sim"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lighting Conditions"}),": Vary lighting in synthetic data generation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Material Properties"}),": Use realistic materials for accurate simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Physics Tuning"}),": Carefully tune physics parameters for realism"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance"}),": Balance visual quality with simulation speed"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Validation"}),": Compare synthetic data with real sensor data"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"exercise",children:"Exercise"}),"\n",(0,a.jsx)(n.p,{children:"Create an Isaac Sim scene that:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Contains a wheeled robot with realistic physics"}),"\n",(0,a.jsx)(n.li,{children:"Includes multiple environmental objects"}),"\n",(0,a.jsx)(n.li,{children:"Generates synthetic RGB and depth data"}),"\n",(0,a.jsx)(n.li,{children:"Implements a simple navigation task"}),"\n",(0,a.jsx)(n.li,{children:"Records performance metrics"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"In this section, you learned:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"How to install and set up Isaac Sim"}),"\n",(0,a.jsx)(n.li,{children:"How to create scenes using USD and Python API"}),"\n",(0,a.jsx)(n.li,{children:"How to integrate Isaac Sim with ROS 2"}),"\n",(0,a.jsx)(n.li,{children:"How to generate synthetic training data"}),"\n",(0,a.jsx)(n.li,{children:"Best practices for effective Isaac Sim usage"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"In the next section, we'll explore Isaac ROS components for perception and navigation."})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>r,x:()=>o});var i=s(6540);const a={},t=i.createContext(a);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);